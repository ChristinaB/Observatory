{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# A Notebook to analyze downloaded gridded climate time-series data \n",
    "\n",
    "## (Case study:  the Sauk-Suiattle Watershed )\n",
    "<img src= \"http://www.sauk-suiattle.com/images/Elliott.jpg\"\n",
    "style=\"float:left;width:150px;padding:20px\">   \n",
    "This data is compiled to digitally observe the Sauk-Suiattle Watershed, powered by HydroShare. <br />\n",
    "<br />\n",
    "Use this Jupyter Notebook to: <br />\n",
    "Migrate data sets from prior data download events,\n",
    "Compute daily, monthly, and annual temperature and precipitation statistics, <br /> \n",
    "Visualize precipitation results relative to the forcing data, <br />\n",
    "Visualize the time-series trends among the gridded cells using different Gridded data products. <br />\n",
    "\n",
    "<br /> <br /> <br /> <img src=\"https://www.washington.edu/brand/files/2014/09/W-Logo_Purple_Hex.png\" style=\"float:right;width:120px;padding:20px\">  \n",
    "#### A Watershed Dynamics Model by the Watershed Dynamics Research Group in the Civil and Environmental Engineering Department at the University of Washington "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.  HydroShare Setup and Preparation\n",
    "\n",
    "To run this notebook, we must import several libaries. These are listed in order of 1) Python standard libraries, 2) hs_utils library provides functions for interacting with HydroShare, including resource querying, dowloading and creation, and 3) the observatory_gridded_hydromet library that is downloaded with this notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!conda install -c conda-forge basemap-data-hires --yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data processing\n",
    "import os\n",
    "import pandas as pd, numpy as np, dask, json\n",
    "import geopandas as gpd\n",
    "import ogh\n",
    "import ogh_meta\n",
    "\n",
    "# data migration library\n",
    "from utilities import hydroshare\n",
    "\n",
    "# plotting and shape libraries\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# silencing warning\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dailymet_bclivneh2013',\n",
       " 'dailymet_livneh2013',\n",
       " 'dailymet_livneh2015',\n",
       " 'dailyvic_livneh2013',\n",
       " 'dailyvic_livneh2015',\n",
       " 'dailywrf_bcsalathe2014',\n",
       " 'dailywrf_salathe2014']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize ogh_meta\n",
    "meta_file = ogh.ogh_meta()\n",
    "\n",
    "sorted(meta_file.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['decision_steps',\n",
       " 'delimiter',\n",
       " 'domain',\n",
       " 'end_date',\n",
       " 'file_format',\n",
       " 'filename_structure',\n",
       " 'reference',\n",
       " 'spatial_resolution',\n",
       " 'start_date',\n",
       " 'subdomain',\n",
       " 'temporal_resolution',\n",
       " 'variable_info',\n",
       " 'variable_list',\n",
       " 'web_protocol']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(meta_file['dailymet_livneh2013'].keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Establish a secure connection with HydroShare by instantiating the hydroshare class that is defined within hs_utils. In addition to connecting with HydroShare, this command also sets and prints environment variables for several parameters that will be useful for saving work back to HydroShare. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding the following system variables:\n",
      "   HS_USR_NAME = jphuong\n",
      "   HS_RES_ID = 70b977e22af544f8a7e5a803935c329c\n",
      "   HS_RES_TYPE = genericresource\n",
      "   JUPYTER_HUB_IP = jupyter.cuahsi.org\n",
      "\n",
      "These can be accessed using the following command: \n",
      "   os.environ[key]\n",
      "\n",
      "   (e.g.)\n",
      "   os.environ[\"HS_USR_NAME\"]  => jphuong\n",
      "\n",
      "The hs_utils library requires a secure connection to your HydroShare account.\n",
      "Enter the HydroShare password for user 'jphuong': ········\n",
      "Successfully established a connection with HydroShare\n",
      "Data will be loaded from and save to:/home/jovyan/work/notebooks/data/70b977e22af544f8a7e5a803935c329c/70b977e22af544f8a7e5a803935c329c/data/contents\n"
     ]
    }
   ],
   "source": [
    "notebookdir = os.getcwd()\n",
    "\n",
    "hs=hydroshare.hydroshare()\n",
    "homedir = hs.getContentPath(os.environ[\"HS_RES_ID\"])\n",
    "os.chdir(homedir)\n",
    "print('Data will be loaded from and save to:'+homedir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are curious about where the data is being downloaded, click on the Jupyter Notebook dashboard icon to return to the File System view.  The homedir directory location printed above is where you can find the data and contents you will download to a HydroShare JupyterHub server.  At the end of this work session, you can migrate this data to the HydroShare iRods server as a Generic Resource. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Get list of gridded climate points for the watershed\n",
    "\n",
    "This example uses a shapefile with the watershed boundary of the Sauk-Suiattle Basin, which is stored in HydroShare at the following url: https://www.hydroshare.org/resource/c532e0578e974201a0bc40a37ef2d284/. \n",
    "\n",
    "The data for our processing routines can be retrieved using the getResourceFromHydroShare function by passing in the global identifier from the url above.  In the next cell, we download this resource from HydroShare, and identify that the points in this resource are available for downloading gridded hydrometeorology data, based on the point shapefile at https://www.hydroshare.org/resource/ef2d82bf960144b4bfb1bae6242bcc7f/, which is for the extent of North America and includes the average elevation for each 1/16 degree grid cell.  The file must include columns with station numbers, latitude, longitude, and elevation. The header of these columns must be FID, LAT, LONG_, and ELEV or RASTERVALU, respectively. The station numbers will be used for the remainder of the code to uniquely reference data from each climate station, as well as to identify minimum, maximum, and average elevation of all of the climate stations.  The webserice is currently set to a URL for the smallest geographic overlapping extent - e.g. WRF for Columbia River Basin (to use a limit using data from a FTP service, treatgeoself() would need to be edited in observatory_gridded_hydrometeorology utility). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This resource already exists in your userspace.\n",
      "c532e0578e974201a0bc40a37ef2d284/\n",
      "|-- c532e0578e974201a0bc40a37ef2d284/\n",
      "|   |-- bagit.txt\n",
      "|   |-- manifest-md5.txt\n",
      "|   |-- readme.txt\n",
      "|   |-- tagmanifest-md5.txt\n",
      "|   |-- data/\n",
      "|   |   |-- resourcemap.xml\n",
      "|   |   |-- resourcemetadata.xml\n",
      "|   |   |-- contents/\n",
      "|   |   |   |-- wbdhub12_17110006_WGS84_Basin.cpg\n",
      "|   |   |   |-- wbdhub12_17110006_WGS84_Basin.shp\n",
      "|   |   |   |-- wbdhub12_17110006_WGS84_Basin.shx\n",
      "|   |   |   |-- wbdhub12_17110006_WGS84_Basin.dbf\n",
      "|   |   |   |-- wbdhub12_17110006_WGS84_Basin.prj\n",
      "\n",
      "Do you want to overwrite these data [Y/n]? y\n",
      "Download Finished                               \n",
      "Successfully downloaded resource c532e0578e974201a0bc40a37ef2d284\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<b>Found the following file(s) associated with this HydroShare resource.</b>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wbdhub12_17110006_WGS84_Basin.cpg<br>wbdhub12_17110006_WGS84_Basin.dbf<br>wbdhub12_17110006_WGS84_Basin.prj<br>wbdhub12_17110006_WGS84_Basin.sbn<br>wbdhub12_17110006_WGS84_Basin.sbx<br>wbdhub12_17110006_WGS84_Basin.shp<br>wbdhub12_17110006_WGS84_Basin.shx"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "These files are stored in a dictionary called <b>hs.content</b> for your convenience.  To access a file, simply issue the following command where MY_FILE is one of the files listed above: <pre>hs.content[\"MY_FILE\"] </pre> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Sauk\n",
    "\"\"\"\n",
    "# Watershed extent\n",
    "hs.getResourceFromHydroShare('c532e0578e974201a0bc40a37ef2d284')\n",
    "sauk = hs.content['wbdhub12_17110006_WGS84_Basin.shp']\n",
    "\n",
    "# reproject the shapefile into WGS84\n",
    "ogh.reprojShapefile(sourcepath=sauk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summarize the file availability from each watershed mapping file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Watershed</th>\n",
       "      <th>Sauk-Suiattle river</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Median elevation in meters [range](No. gridded cells)</th>\n",
       "      <th>1171[164-2216] (n=99)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dailymet_livneh2013</th>\n",
       "      <td>1171[164-2216] (n=99)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dailymet_bclivneh2013</th>\n",
       "      <td>1171[164-2216] (n=99)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dailymet_livneh2015</th>\n",
       "      <td>1171[164-2216] (n=99)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dailyvic_livneh2013</th>\n",
       "      <td>1171[164-2216] (n=99)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dailyvic_livneh2015</th>\n",
       "      <td>1171[164-2216] (n=99)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dailywrf_salathe2014</th>\n",
       "      <td>1171[164-2216] (n=99)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dailywrf_bcsalathe2014</th>\n",
       "      <td>1171[164-2216] (n=99)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Watershed                                                Sauk-Suiattle river\n",
       "Median elevation in meters [range](No. gridded cells)  1171[164-2216] (n=99)\n",
       "dailymet_livneh2013                                    1171[164-2216] (n=99)\n",
       "dailymet_bclivneh2013                                  1171[164-2216] (n=99)\n",
       "dailymet_livneh2015                                    1171[164-2216] (n=99)\n",
       "dailyvic_livneh2013                                    1171[164-2216] (n=99)\n",
       "dailyvic_livneh2015                                    1171[164-2216] (n=99)\n",
       "dailywrf_salathe2014                                   1171[164-2216] (n=99)\n",
       "dailywrf_bcsalathe2014                                 1171[164-2216] (n=99)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# map the mappingfiles from usecase1\n",
    "mappingfile1 = os.path.join(homedir,'Sauk_mappingfile.csv')\n",
    "\n",
    "t1 = ogh.mappingfileSummary(listofmappingfiles = [mappingfile1], \n",
    "                            listofwatershednames = ['Sauk-Suiattle river'],\n",
    "                            meta_file=meta_file)\n",
    "\n",
    "t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "files=[]\n",
    "files.append(mappingfile1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.  Compare Hydrometeorology \n",
    "\n",
    "This section performs computations and generates plots of the Livneh 2013, Livneh 2016, and WRF 2014 temperature and precipitation data in order to compare them with each other and observations. The generated plots are automatically downloaded and saved as .png files in the \"plots\" folder of the user's home directory and inline in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('1950-01-01', '2011-12-31')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Livneh et al., 2013\n",
    "dr1 = meta_file['dailymet_livneh2013']\n",
    "\n",
    "# Livneh et al., 2015\n",
    "dr2 = meta_file['dailymet_livneh2015']\n",
    "\n",
    "# define overlapping time window\n",
    "dr = ogh.overlappingDates(date_set1=tuple([dr1['start_date'], dr1['end_date']]), \n",
    "                          date_set2=tuple([dr2['start_date'], dr2['end_date']]))\n",
    "dr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### INPUT: gridded meteorology from Jupyter Hub folders\n",
    "Data frames for each set of data are stored in a dictionary. The inputs to gridclim_dict() include the folder location and name of the hydrometeorology data, the file start and end, the analysis start and end, and the elevation band to be included in the analsyis (max and min elevation). <br/>  \n",
    "\n",
    "#### Create a dictionary of climate variables for the long-term mean (ltm) using the default elevation option of calculating a high, mid, and low elevation average.  The dictionary here is initialized with the Livneh et al., 2013 dataset with a dictionary output 'ltm_3bands', which is used as an input to the second time we run gridclim_dict(), to add the Salathe et al., 2014 data to the same dictionary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data files within elevation range (164.0:2216.0): 99\n",
      "EVAP dataframe reading to start: 0:00:00.183471\n",
      "EVAP dataframe reading complete:0:00:02.513297\n",
      "RUNOFF dataframe reading to start: 0:00:02.689769\n",
      "RUNOFF dataframe reading complete:0:00:04.567765\n",
      "BASEFLOW dataframe reading to start: 0:00:04.740503\n",
      "BASEFLOW dataframe reading complete:0:00:06.297634\n",
      "SMTOP dataframe reading to start: 0:00:06.473216\n",
      "SMTOP dataframe reading complete:0:00:08.039287\n",
      "SMMID dataframe reading to start: 0:00:08.213095\n",
      "SMMID dataframe reading complete:0:00:09.751738\n",
      "SMBOT dataframe reading to start: 0:00:09.931664\n",
      "SMBOT dataframe reading complete:0:00:11.481316\n",
      "SWE dataframe reading to start: 0:00:11.657612\n",
      "SWE dataframe reading complete:0:00:13.298564\n",
      "WDEW dataframe reading to start: 0:00:13.477774\n",
      "WDEW dataframe reading complete:0:00:15.151872\n",
      "SENSIBLE dataframe reading to start: 0:00:15.325349\n",
      "SENSIBLE dataframe reading complete:0:00:16.929763\n",
      "LATENT dataframe reading to start: 0:00:17.102648\n",
      "LATENT dataframe reading complete:0:00:18.689436\n",
      "GRNDFLUX dataframe reading to start: 0:00:18.866046\n",
      "GRNDFLUX dataframe reading complete:0:00:20.465490\n",
      "RNET dataframe reading to start: 0:00:20.643869\n",
      "RNET dataframe reading complete:0:00:22.220151\n",
      "RADTEMP dataframe reading to start: 0:00:22.397792\n",
      "RADTEMP dataframe reading complete:0:00:24.004665\n",
      "PREC dataframe reading to start: 0:00:24.182606\n",
      "PREC dataframe reading complete:0:00:25.721963\n",
      "EVAP_dailyvic_livneh2013 calculations completed in 0:00:00.216471\n",
      "RUNOFF_dailyvic_livneh2013 calculations completed in 0:00:00.187974\n",
      "BASEFLOW_dailyvic_livneh2013 calculations completed in 0:00:00.189834\n",
      "SMTOP_dailyvic_livneh2013 calculations completed in 0:00:00.189251\n",
      "SMMID_dailyvic_livneh2013 calculations completed in 0:00:00.189166\n",
      "SMBOT_dailyvic_livneh2013 calculations completed in 0:00:00.187785\n",
      "SWE_dailyvic_livneh2013 calculations completed in 0:00:00.188334\n",
      "WDEW_dailyvic_livneh2013 calculations completed in 0:00:00.189356\n",
      "SENSIBLE_dailyvic_livneh2013 calculations completed in 0:00:00.189060\n",
      "LATENT_dailyvic_livneh2013 calculations completed in 0:00:00.186923\n",
      "GRNDFLUX_dailyvic_livneh2013 calculations completed in 0:00:00.187882\n",
      "RNET_dailyvic_livneh2013 calculations completed in 0:00:00.188030\n",
      "RADTEMP_dailyvic_livneh2013 calculations completed in 0:00:00.187298\n",
      "PREC_dailyvic_livneh2013 calculations completed in 0:00:00.184907\n",
      "Number of data files within elevation range (164.0:2216.0): 99\n",
      "EVAP dataframe reading to start: 0:00:00.180395\n",
      "EVAP dataframe reading complete:0:00:01.660520\n",
      "RUNOFF dataframe reading to start: 0:00:01.837236\n",
      "RUNOFF dataframe reading complete:0:00:03.049347\n",
      "BASEFLOW dataframe reading to start: 0:00:03.223564\n",
      "BASEFLOW dataframe reading complete:0:00:04.452364\n",
      "SMTOP dataframe reading to start: 0:00:04.629236\n",
      "SMTOP dataframe reading complete:0:00:05.858581\n",
      "SMMID dataframe reading to start: 0:00:06.032452\n",
      "SMMID dataframe reading complete:0:00:07.257515\n",
      "SMBOT dataframe reading to start: 0:00:07.432651\n",
      "SMBOT dataframe reading complete:0:00:08.673684\n",
      "SWE dataframe reading to start: 0:00:08.849194\n",
      "SWE dataframe reading complete:0:00:10.057265\n",
      "WDEW dataframe reading to start: 0:00:10.246272\n",
      "WDEW dataframe reading complete:0:00:11.569778\n",
      "SENSIBLE dataframe reading to start: 0:00:11.743876\n",
      "SENSIBLE dataframe reading complete:0:00:12.952719\n",
      "LATENT dataframe reading to start: 0:00:13.127496\n",
      "LATENT dataframe reading complete:0:00:14.334860\n",
      "GRNDFLUX dataframe reading to start: 0:00:14.509879\n",
      "GRNDFLUX dataframe reading complete:0:00:15.754057\n",
      "RNET dataframe reading to start: 0:00:15.929818\n",
      "RNET dataframe reading complete:0:00:17.123794\n",
      "PETTALL dataframe reading to start: 0:00:17.301905\n",
      "PETTALL dataframe reading complete:0:00:18.509453\n",
      "PETSHORT dataframe reading to start: 0:00:18.683273\n",
      "PETSHORT dataframe reading complete:0:00:19.875049\n",
      "PETNATVEG dataframe reading to start: 0:00:20.053507\n",
      "PETNATVEG dataframe reading complete:0:00:21.401971\n",
      "EVAP_dailyvic_livneh2015 calculations completed in 0:00:00.192257\n",
      "RUNOFF_dailyvic_livneh2015 calculations completed in 0:00:00.187085\n",
      "BASEFLOW_dailyvic_livneh2015 calculations completed in 0:00:00.189077\n",
      "SMTOP_dailyvic_livneh2015 calculations completed in 0:00:00.185321\n",
      "SMMID_dailyvic_livneh2015 calculations completed in 0:00:00.187988\n",
      "SMBOT_dailyvic_livneh2015 calculations completed in 0:00:00.191397\n",
      "SWE_dailyvic_livneh2015 calculations completed in 0:00:00.187915\n",
      "WDEW_dailyvic_livneh2015 calculations completed in 0:00:00.189421\n",
      "SENSIBLE_dailyvic_livneh2015 calculations completed in 0:00:00.189160\n",
      "LATENT_dailyvic_livneh2015 calculations completed in 0:00:00.187395\n",
      "GRNDFLUX_dailyvic_livneh2015 calculations completed in 0:00:00.188626\n",
      "RNET_dailyvic_livneh2015 calculations completed in 0:00:00.189336\n",
      "PETTALL_dailyvic_livneh2015 calculations completed in 0:00:00.188867\n",
      "PETSHORT_dailyvic_livneh2015 calculations completed in 0:00:00.185106\n",
      "PETNATVEG_dailyvic_livneh2015 calculations completed in 0:00:00.185713\n",
      "CPU times: user 5min 3s, sys: 1min 20s, total: 6min 24s\n",
      "Wall time: 52.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ltm = ogh.gridclim_dict(mappingfile=mappingfile1,\n",
    "                        metadata=meta_file,\n",
    "                        dataset='dailyvic_livneh2013',\n",
    "                        subset_start_date=dr[0],\n",
    "                        subset_end_date=dr[1])\n",
    "\n",
    "ltm = ogh.gridclim_dict(mappingfile=mappingfile1,\n",
    "                        metadata=meta_file,\n",
    "                        dataset='dailyvic_livneh2015',\n",
    "                        subset_start_date=dr[0],\n",
    "                        subset_end_date=dr[1],\n",
    "                        df_dict=ltm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>desc</th>\n",
       "      <th>dtypes</th>\n",
       "      <th>units</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BASEFLOW</th>\n",
       "      <td>Baseflow</td>\n",
       "      <td>float64</td>\n",
       "      <td>mm/s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DAY</th>\n",
       "      <td>day</td>\n",
       "      <td>int8</td>\n",
       "      <td>day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EVAP</th>\n",
       "      <td>Total ET rate-- includes Canopy, Sub-canopy Ev...</td>\n",
       "      <td>float64</td>\n",
       "      <td>mm/s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GRNDFLUX</th>\n",
       "      <td>Net heat flux into ground</td>\n",
       "      <td>float64</td>\n",
       "      <td>W/m^2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LATENT</th>\n",
       "      <td>Net latent heat flux</td>\n",
       "      <td>float64</td>\n",
       "      <td>W/m^2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MONTH</th>\n",
       "      <td>month</td>\n",
       "      <td>int8</td>\n",
       "      <td>mo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PREC</th>\n",
       "      <td>Incoming precipitation rate</td>\n",
       "      <td>float64</td>\n",
       "      <td>mm/s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RADTEMP</th>\n",
       "      <td>Mean radiative surface temperature</td>\n",
       "      <td>float64</td>\n",
       "      <td>K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RNET</th>\n",
       "      <td>Net downward radiation flux</td>\n",
       "      <td>float64</td>\n",
       "      <td>W/m^2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RUNOFF</th>\n",
       "      <td>Runoff</td>\n",
       "      <td>float64</td>\n",
       "      <td>mm/s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SENSIBLE</th>\n",
       "      <td>Net sensible heat flux</td>\n",
       "      <td>float64</td>\n",
       "      <td>W/m^2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SMBOT</th>\n",
       "      <td>Soil moisture bottom layer</td>\n",
       "      <td>float64</td>\n",
       "      <td>mm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SMMID</th>\n",
       "      <td>Soil moisture middle layer</td>\n",
       "      <td>float64</td>\n",
       "      <td>mm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SMTOP</th>\n",
       "      <td>Soil moisture top layer</td>\n",
       "      <td>float64</td>\n",
       "      <td>mm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SWE</th>\n",
       "      <td>Snow water equivalent (SWE)</td>\n",
       "      <td>float64</td>\n",
       "      <td>mm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WDEW</th>\n",
       "      <td>Canopy water</td>\n",
       "      <td>float64</td>\n",
       "      <td>mm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YEAR</th>\n",
       "      <td>year</td>\n",
       "      <td>int8</td>\n",
       "      <td>yr</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       desc   dtypes  units\n",
       "BASEFLOW                                           Baseflow  float64   mm/s\n",
       "DAY                                                     day     int8    day\n",
       "EVAP      Total ET rate-- includes Canopy, Sub-canopy Ev...  float64   mm/s\n",
       "GRNDFLUX                          Net heat flux into ground  float64  W/m^2\n",
       "LATENT                                 Net latent heat flux  float64  W/m^2\n",
       "MONTH                                                 month     int8     mo\n",
       "PREC                            Incoming precipitation rate  float64   mm/s\n",
       "RADTEMP                  Mean radiative surface temperature  float64      K\n",
       "RNET                            Net downward radiation flux  float64  W/m^2\n",
       "RUNOFF                                               Runoff  float64   mm/s\n",
       "SENSIBLE                             Net sensible heat flux  float64  W/m^2\n",
       "SMBOT                            Soil moisture bottom layer  float64     mm\n",
       "SMMID                            Soil moisture middle layer  float64     mm\n",
       "SMTOP                               Soil moisture top layer  float64     mm\n",
       "SWE                             Snow water equivalent (SWE)  float64     mm\n",
       "WDEW                                           Canopy water  float64     mm\n",
       "YEAR                                                   year     int8     yr"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# explain the livneh et al. 2013 daily VIC variables\n",
    "pd.DataFrame.from_dict(meta_file['dailyvic_livneh2013']['variable_info']).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>desc</th>\n",
       "      <th>dtypes</th>\n",
       "      <th>units</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BASEFLOW</th>\n",
       "      <td>Baseflow</td>\n",
       "      <td>float64</td>\n",
       "      <td>mm/day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DAY</th>\n",
       "      <td>day</td>\n",
       "      <td>int8</td>\n",
       "      <td>day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EVAP</th>\n",
       "      <td>Total ET rate-- includes Canopy, Sub-canopy Ev...</td>\n",
       "      <td>float64</td>\n",
       "      <td>mm/day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GRNDFLUX</th>\n",
       "      <td>Net heat flux into ground</td>\n",
       "      <td>float64</td>\n",
       "      <td>W/m^2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LATENT</th>\n",
       "      <td>Net latent heat flux</td>\n",
       "      <td>float64</td>\n",
       "      <td>W/m^2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MONTH</th>\n",
       "      <td>month</td>\n",
       "      <td>int8</td>\n",
       "      <td>mo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PETNATVEG</th>\n",
       "      <td>Potential Evapotranspiration from current vege...</td>\n",
       "      <td>float64</td>\n",
       "      <td>mm/day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PETSHORT</th>\n",
       "      <td>Potential Evapotranspiration from short crop (...</td>\n",
       "      <td>float64</td>\n",
       "      <td>mm/day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PETTALL</th>\n",
       "      <td>Potential Evapotranspiration from tall crop (A...</td>\n",
       "      <td>float64</td>\n",
       "      <td>mm/day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RNET</th>\n",
       "      <td>Net downward radiation flux</td>\n",
       "      <td>float64</td>\n",
       "      <td>W/m^2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RUNOFF</th>\n",
       "      <td>Runoff</td>\n",
       "      <td>float64</td>\n",
       "      <td>mm/day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SENSIBLE</th>\n",
       "      <td>Net sensible heat flux</td>\n",
       "      <td>float64</td>\n",
       "      <td>W/m^2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SMBOT</th>\n",
       "      <td>Soil moisture bottom layer</td>\n",
       "      <td>float64</td>\n",
       "      <td>mm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SMMID</th>\n",
       "      <td>Soil moisture middle layer</td>\n",
       "      <td>float64</td>\n",
       "      <td>mm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SMTOP</th>\n",
       "      <td>Soil moisture top layer</td>\n",
       "      <td>float64</td>\n",
       "      <td>mm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SWE</th>\n",
       "      <td>Snow water equivalent (SWE)</td>\n",
       "      <td>float64</td>\n",
       "      <td>mm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WDEW</th>\n",
       "      <td>Canopy water</td>\n",
       "      <td>float64</td>\n",
       "      <td>mm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YEAR</th>\n",
       "      <td>year</td>\n",
       "      <td>int8</td>\n",
       "      <td>yr</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        desc   dtypes   units\n",
       "BASEFLOW                                            Baseflow  float64  mm/day\n",
       "DAY                                                      day     int8     day\n",
       "EVAP       Total ET rate-- includes Canopy, Sub-canopy Ev...  float64  mm/day\n",
       "GRNDFLUX                           Net heat flux into ground  float64   W/m^2\n",
       "LATENT                                  Net latent heat flux  float64   W/m^2\n",
       "MONTH                                                  month     int8      mo\n",
       "PETNATVEG  Potential Evapotranspiration from current vege...  float64  mm/day\n",
       "PETSHORT   Potential Evapotranspiration from short crop (...  float64  mm/day\n",
       "PETTALL    Potential Evapotranspiration from tall crop (A...  float64  mm/day\n",
       "RNET                             Net downward radiation flux  float64   W/m^2\n",
       "RUNOFF                                                Runoff  float64  mm/day\n",
       "SENSIBLE                              Net sensible heat flux  float64   W/m^2\n",
       "SMBOT                             Soil moisture bottom layer  float64      mm\n",
       "SMMID                             Soil moisture middle layer  float64      mm\n",
       "SMTOP                                Soil moisture top layer  float64      mm\n",
       "SWE                              Snow water equivalent (SWE)  float64      mm\n",
       "WDEW                                            Canopy water  float64      mm\n",
       "YEAR                                                    year     int8      yr"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_dict(meta_file['dailyvic_livneh2015']['variable_info']).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute daily streamflow as a function of daily Baseflow and Runoff \n",
    "ltm['STREAMFLOW_dailyvic_livneh2013']=ltm['BASEFLOW_dailyvic_livneh2013']+ltm['RUNOFF_dailyvic_livneh2013']\n",
    "ltm['STREAMFLOW_dailyvic_livneh2015']=ltm['BASEFLOW_dailyvic_livneh2015']+ltm['RUNOFF_dailyvic_livneh2015']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ltm['STREAMFLOW_dailyvic_livneh2013'].iloc[:5,:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ltm['STREAMFLOW_dailyvic_livneh2015'].iloc[:5,:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ltm['STREAMFLOW_dailyvic_livneh2013'].unstack().count()/99/12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ltm['STREAMFLOW_dailyvic_livneh2013'].unstack().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ltm['STREAMFLOW_dailyvic_livneh2013'].unstack().min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# station with the max streamflow (mmday)\n",
    "ltm['STREAMFLOW_dailyvic_livneh2013'].unstack().loc[ltm['STREAMFLOW_dailyvic_livneh2013'].unstack()==ltm['STREAMFLOW_dailyvic_livneh2013'].unstack().max(),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ltm['STREAMFLOW_dailyvic_livneh2013'].iloc[:,97].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ltm['STREAMFLOW_dailyvic_livneh2013'].iloc[:,97].hist(bins=1000, figsize=(10,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ltm['EXCEED0.01_mmday_dailyvic_livneh2013'].iloc[:,97]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ltm['STREAMFLOW_dailyvic_livneh2013'].iloc[:,1].groupby(pd.TimeGrouper('m')).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(0,12):\n",
    "    print(j, ltm['EXCEED0.01_mmday_dailyvic_livneh2013'].iloc[j,:].min(), ltm['EXCEED0.01_mmday_dailyvic_livneh2013'].iloc[j,:].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform units from mm/s to mm/day\n",
    "ltm['STREAMFLOW_dailyvic_livneh2013'] = ltm['STREAMFLOW_dailyvic_livneh2013']*(24*60*60)\n",
    "ltm['STREAMFLOW_dailyvic_livneh2013'].iloc[:5,:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # compute the mean gridded cell area\n",
    "# gcSA, gcSA_sd = ogh.computeGCSurfaceArea(shapefile=sauk, \n",
    "#                                          spatial_resolution=1/16,\n",
    "#                                          vardf=ltm['STREAMFLOW_dailyvic_livneh2013'])\n",
    "\n",
    "# gcSA, gcSA_sd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # plot the distribution of total monthly precipitation by month across stations\n",
    "\n",
    "# # Exceedance Probability\n",
    "# for exceedance in [0.01, 0.1, 1, 10]:\n",
    "\n",
    "#     # compute exceedance probability (Livneh 2013)\n",
    "#     ltm = ogh.monthlyExceedence_cfs(df_dict=ltm,\n",
    "#                                     daily_streamflow_dfname='STREAMFLOW_dailyvic_livneh2013',\n",
    "#                                     gridcell_area=gcSA,\n",
    "#                                     exceedance=exceedance)\n",
    "    \n",
    "#     # compute exceedance probability (Livneh 2015)\n",
    "#     ltm = ogh.monthlyExceedence_cfs(df_dict=ltm,\n",
    "#                                     daily_streamflow_dfname='STREAMFLOW_dailyvic_livneh2015',\n",
    "#                                     gridcell_area=gcSA,\n",
    "#                                     exceedance=exceedance)\n",
    "\n",
    "    \n",
    "    \n",
    "#     # designate output file path\n",
    "#     outfile=os.path.join(homedir, 'SaukExceedance{0}_livneh2013.png'.format(exceedance))\n",
    "#     files.append(outfile)\n",
    "    \n",
    "#     # render monthly exceedance probability distributions\n",
    "#     ogh.renderValueInBoxplot(vardf=ltm['EXCEED{0}_dailyvic_livneh2013'.format(exceedance)],\n",
    "#                              vmin=ltm['EXCEED{0}_dailyvic_livneh2015'.format(exceedance)].as_matrix().min(),\n",
    "#                              vmax=ltm['EXCEED{0}_dailyvic_livneh2015'.format(exceedance)].as_matrix().max(),\n",
    "#                              outfilepath=outfile,\n",
    "#                              plottitle='Sauk-Suiattle {0}% Exceedance Probability\\nLivneh et al. 2013'.format(exceedance),\n",
    "#                              time_steps='month',\n",
    "#                              wateryear=True,\n",
    "#                              value_name='{0}% Exceedance Probability (cfs)'.format(exceedance),\n",
    "#                              cmap='seismic_r',\n",
    "#                              figsize=(15,6))\n",
    "    \n",
    "    \n",
    "    \n",
    "#     # designate output file path\n",
    "#     outfile=os.path.join(homedir, 'SaukExceedance{0}_livneh2015.png'.format(exceedance))\n",
    "#     files.append(outfile)\n",
    "    \n",
    "#     # render monthly exceedance probability distributions\n",
    "#     ogh.renderValueInBoxplot(vardf=ltm['EXCEED{0}_dailyvic_livneh2015'.format(exceedance)],\n",
    "#                              vmin=ltm['EXCEED{0}_dailyvic_livneh2015'.format(exceedance)].as_matrix().min(),\n",
    "#                              vmax=ltm['EXCEED{0}_dailyvic_livneh2015'.format(exceedance)].as_matrix().max(),\n",
    "#                              outfilepath=outfile,\n",
    "#                              plottitle='Sauk-Suiattle {0}% Exceedance Probability\\nLivneh et al. 2015'.format(exceedance),\n",
    "#                              time_steps='month',\n",
    "#                              wateryear=True,\n",
    "#                              value_name='{0}% Exceedance Probability (cfs)'.format(exceedance),\n",
    "#                              cmap='seismic_r',\n",
    "#                              figsize=(15,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#### redo for mm/day as the exceedance probability from runoff\n",
    "# plot the distribution of total monthly precipitation by month across stations\n",
    "\n",
    "# Exceedance Probability\n",
    "for exceedance in [0.01, 10, 90]:\n",
    "\n",
    "    # compute exceedance probability (Livneh 2013)\n",
    "    ltm = ogh.monthlyExceedence_mmday(df_dict=ltm,\n",
    "                                    daily_streamflow_dfname='STREAMFLOW_dailyvic_livneh2013',\n",
    "                                    exceedance=exceedance)\n",
    "    \n",
    "    # compute exceedance probability (Livneh 2015)\n",
    "    ltm = ogh.monthlyExceedence_mmday(df_dict=ltm,\n",
    "                                    daily_streamflow_dfname='STREAMFLOW_dailyvic_livneh2015',\n",
    "                                    exceedance=exceedance)\n",
    "\n",
    "    \n",
    "    \n",
    "    # designate output file path\n",
    "    outfile=os.path.join(homedir, 'SaukExceedance{0}_livneh2013.png'.format(exceedance))\n",
    "    files.append(outfile)\n",
    "    \n",
    "    # render monthly exceedance probability distributions\n",
    "    ogh.renderValueInBoxplot(vardf=ltm['EXCEED{0}_mmday_dailyvic_livneh2013'.format(exceedance)],\n",
    "                             vmin=ltm['EXCEED{0}_mmday_dailyvic_livneh2015'.format(exceedance)].as_matrix().min(),\n",
    "                             vmax=ltm['EXCEED{0}_mmday_dailyvic_livneh2015'.format(exceedance)].as_matrix().max()+1,\n",
    "                             outfilepath=outfile,\n",
    "                             plottitle='Sauk-Suiattle {0}% Exceedance Probability\\nLivneh et al. 2013'.format(exceedance),\n",
    "                             time_steps='month',\n",
    "                             wateryear=True,\n",
    "                             value_name='{0}% Exceedance Probability (mm/day)'.format(exceedance),\n",
    "                             cmap='seismic_r',\n",
    "                             figsize=(15,6))\n",
    "    \n",
    "    \n",
    "    \n",
    "    # designate output file path\n",
    "    outfile=os.path.join(homedir, 'SaukExceedance{0}_livneh2015.png'.format(exceedance))\n",
    "    files.append(outfile)\n",
    "    \n",
    "    # render monthly exceedance probability distributions\n",
    "    ogh.renderValueInBoxplot(vardf=ltm['EXCEED{0}_mmday_dailyvic_livneh2015'.format(exceedance)],\n",
    "                             vmin=ltm['EXCEED{0}_mmday_dailyvic_livneh2015'.format(exceedance)].as_matrix().min(),\n",
    "                             vmax=ltm['EXCEED{0}_mmday_dailyvic_livneh2015'.format(exceedance)].as_matrix().max()+1,\n",
    "                             outfilepath=outfile,\n",
    "                             plottitle='Sauk-Suiattle {0}% Exceedance Probability\\nLivneh et al. 2015'.format(exceedance),\n",
    "                             time_steps='month',\n",
    "                             wateryear=True,\n",
    "                             value_name='{0}% Exceedance Probability (mm/day)'.format(exceedance),\n",
    "                             cmap='seismic_r',\n",
    "                             figsize=(15,6))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# loop through each month to compute the 10% Exceedance Probability\n",
    "for eachmonth in [11, 7]:\n",
    "    monthlabel = pd.datetime.strptime(str(eachmonth), '%m')\n",
    "\n",
    "    # generate outfile path\n",
    "    outfile=os.path.join(homedir,'sauk{0}exceed0.01_livneh2013.png'.format(monthlabel.strftime('%b')))\n",
    "    files.append(outfile)\n",
    "    \n",
    "    ogh.renderValuesInPoints(vardf=ltm['EXCEED0.01_mmday_dailyvic_livneh2013'],\n",
    "                             vardf_dateindex=eachmonth, \n",
    "                             shapefile=sauk,\n",
    "                             outfilepath=outfile, \n",
    "                             plottitle='Sauk {0} 0.01% Exceedance Probability'.format(monthlabel.strftime('%B')),\n",
    "                             colorbar_label='millimeters per day',\n",
    "                             cmap='seismic_r')\n",
    "    \n",
    "    # generate outfile path\n",
    "    outfile=os.path.join(homedir,'sauk{0}exceed10_livneh2013.png'.format(monthlabel.strftime('%b')))\n",
    "    files.append(outfile)\n",
    "    \n",
    "    ogh.renderValuesInPoints(vardf=ltm['EXCEED10_mmday_dailyvic_livneh2013'],\n",
    "                             vardf_dateindex=eachmonth, \n",
    "                             shapefile=sauk,\n",
    "                             outfilepath=outfile, \n",
    "                             plottitle='Sauk {0} 10% Exceedance Probability'.format(monthlabel.strftime('%B')),\n",
    "                             colorbar_label='millimeters per day',\n",
    "                             cmap='seismic_r')\n",
    "    \n",
    "    \n",
    "    # generate outfile path\n",
    "    outfile=os.path.join(homedir,'sauk{0}exceed90_livneh2013.png'.format(monthlabel.strftime('%b')))\n",
    "    files.append(outfile)\n",
    "    \n",
    "    ogh.renderValuesInPoints(vardf=ltm['EXCEED90_mmday_dailyvic_livneh2013'],\n",
    "                             vardf_dateindex=eachmonth, \n",
    "                             shapefile=sauk,\n",
    "                             outfilepath=outfile, \n",
    "                             plottitle='Sauk {0} 90% Exceedance Probability'.format(monthlabel.strftime('%B')),\n",
    "                             colorbar_label='millimeters per day',\n",
    "                             cmap='seismic_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ltm['EXCEED0.01_mmday_dailyvic_livneh2013']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # loop through each month to compute the 10% Exceedance Probability\n",
    "# for eachmonth in [10, 11, 7]:\n",
    "#     monthlabel = pd.datetime.strptime(str(eachmonth), '%m')\n",
    "\n",
    "#     # generate outfile path\n",
    "#     outfile=os.path.join(homedir,'sauk{0}exceed0.01_livneh2013.png'.format(monthlabel.strftime('%b')))\n",
    "#     files.append(outfile)\n",
    "    \n",
    "#     # render spatial map\n",
    "#     ogh.renderValuesInPoints(vardf=ltm['EXCEED0.01_dailyvic_livneh2013'],\n",
    "#                              vardf_dateindex=eachmonth, \n",
    "#                              shapefile=sauk,\n",
    "#                              outfilepath=outfile, \n",
    "#                              plottitle='Sauk {0} 0.01% Exceedance Probability'.format(monthlabel.strftime('%B')),\n",
    "#                              colorbar_label='cubic feet per second',\n",
    "#                              cmap='seismic_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # loop through each month to compute the 10% Exceedance Probability\n",
    "# for eachmonth in [10, 11, 1, 2, 4, 5, 7, 8]:\n",
    "#     monthlabel = pd.datetime.strptime(str(eachmonth), '%m')\n",
    "\n",
    "#     # generate outfile path\n",
    "#     outfile=os.path.join(homedir,'sauk{0}exceed0.01_livneh2013.png'.format(monthlabel.strftime('%b')))\n",
    "#     files.append(outfile)\n",
    "    \n",
    "#     # render spatial map\n",
    "#     ogh.renderValuesInPoints_scale(vardf=ltm['EXCEED0.01_dailyvic_livneh2013'],\n",
    "#                                    vardf_dateindex=eachmonth, \n",
    "#                                    shapefile=sauk,\n",
    "#                                    outfilepath=outfile, \n",
    "#                                    plottitle='Sauk {0} 0.01% Exceedance Probability'.format(monthlabel.strftime('%B')),\n",
    "#                                    colorbar_label='cubic feet per second',\n",
    "#                                    vardfmax=ltm['EXCEED0.01_dailyvic_livneh2013'].as_matrix().max(),\n",
    "#                                    vardfmin=ltm['EXCEED0.01_dailyvic_livneh2013'].as_matrix().min(),\n",
    "#                                    cmap='seismic_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # compute average computations for streamflow in cfs units\n",
    "# ltm=ogh.aggregate_space_time_average(df_dict=ltm,\n",
    "#                                      suffix='cfs_STREAMFLOW_dailyvic_livneh2013',\n",
    "#                                      start_date=ltm['cfs_STREAMFLOW_dailyvic_livneh2013'].index[0],\n",
    "#                                      end_date=ltm['cfs_STREAMFLOW_dailyvic_livneh2013'].index[-1])\n",
    "\n",
    "# # compute average computations for streamflow in cfs units\n",
    "# ltm=ogh.aggregate_space_time_average(df_dict=ltm,\n",
    "#                                      suffix='cfs_STREAMFLOW_dailyvic_livneh2015',\n",
    "#                                      start_date=ltm['cfs_STREAMFLOW_dailyvic_livneh2015'].index[0],\n",
    "#                                      end_date=ltm['cfs_STREAMFLOW_dailyvic_livneh2015'].index[-1])\n",
    "\n",
    "# sorted(ltm.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # generate the plot dimensions\n",
    "# ax1 = plt.subplot(1,1,1)\n",
    "\n",
    "# # plot the average daily streamflow by year\n",
    "# ltm['year_cfs_STREAMFLOW_dailyvic_livneh2013'].plot(legend=False, figsize=(16,5), ax=ax1)\n",
    "\n",
    "# # set yaxis label\n",
    "# ax1.set_ylabel('Average daily streamflow (cfs)')\n",
    "\n",
    "# # arrange the xaxis xtick labels\n",
    "# ax1.set_xticks(ticks=ltm['year_cfs_STREAMFLOW_dailyvic_livneh2013'].index)\n",
    "# ax1.xaxis.set_ticklabels(ticklabels=ltm['year_cfs_STREAMFLOW_dailyvic_livneh2013'].index, rotation=90)\n",
    "\n",
    "# # set title\n",
    "# ax1.set_title('Sauk-Suiattle Average daily streamflow (cfs) by year')\n",
    "# outfile=os.path.join(homedir,'average_daily_streamflow_annually.png')\n",
    "# files.append(outfile)\n",
    "# plt.savefig(outfile)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # generate the plot dimensions\n",
    "# ax2 = plt.subplot(1,1,1)\n",
    "\n",
    "# # plot the max daily streamflow across stations by year\n",
    "# df = ltm['cfs_STREAMFLOW_dailyvic_livneh2013'].groupby(ltm['cfs_STREAMFLOW_dailyvic_livneh2013'].index.year).max()\n",
    "# df.plot(legend=False, figsize=(16,5), ax=ax2, alpha=0.4)\n",
    "\n",
    "# # add the highest streamflow across stations\n",
    "# df.max(axis=1).plot(legend=False, color='r', ax=ax2)\n",
    "\n",
    "# # set yaxis label\n",
    "# ax2.set_ylabel('Max annual streamflow (cfs)')\n",
    "\n",
    "# # arrange the xaxis xtick labels\n",
    "# ax2.set_xticks(ticks=df.index)\n",
    "# ax2.xaxis.set_ticklabels(ticklabels=df.index, rotation=90)\n",
    "\n",
    "# # set title\n",
    "# ax2.set_title('Sauk-Suiattle Max annual streamflow (cfs) by year')\n",
    "\n",
    "# outfile=os.path.join(homedir,'max_streamflow_annually.png')\n",
    "# files.append(outfile)\n",
    "# plt.savefig(outfile)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Save the results back into HydroShare\n",
    "<a name=\"creation\"></a>\n",
    "\n",
    "Using the `hs_utils` library, the results of the Geoprocessing steps above can be saved back into HydroShare.  First, define all of the required metadata for resource creation, i.e. *title*, *abstract*, *keywords*, *content files*.  In addition, we must define the type of resource that will be created, in this case *genericresource*.  \n",
    "\n",
    "***Note:*** Make sure you save the notebook at this point, so that all notebook changes will be saved into the new HydroShare resource."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the dictionary of dataframes\n",
    "outfile=os.path.join(homedir, 'ltm_livneh2013vic.json')\n",
    "files.append(outfile)\n",
    "\n",
    "ogh.saveDictOfDf(dictionaryObject=ltm, outfilepath=outfile)\n",
    "\n",
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each file downloaded onto the server folder, move to a new HydroShare Generic Resource\n",
    "title = 'Exceedance Probability within Sauk-Suiattle'\n",
    "abstract = 'This the output from the TreatGeoSelf utility integration notebook.'\n",
    "keywords = ['Sauk', 'climate', 'Streamflow','flood risk prediction','hydromet','watershed'] \n",
    "rtype = 'genericresource'  \n",
    "\n",
    "# create the new resource\n",
    "resource_id = hs.createHydroShareResource(title=title,\n",
    "                                          abstract=abstract,\n",
    "                                          keywords=keywords,\n",
    "                                          resource_type=rtype,\n",
    "                                          content_files=files,\n",
    "                                          public=False)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
